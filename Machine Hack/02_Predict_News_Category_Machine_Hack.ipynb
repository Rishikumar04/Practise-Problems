{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Hack Predict News Category Hackathon\n",
    "**Link:**https://machinehack.com/hackathons/predict_the_news_category_hackathon/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('Data_Train.xlsx')\n",
    "\n",
    "test_df = pd.read_excel('Data_Test.xlsx')\n",
    "\n",
    "sample_df = pd.read_excel('Sample_submission.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Facebook, WhatsApp and Twitter have overhauled...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>We will leave no stone unturned to make the au...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>The whole feels like a giant set, stately and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7462</th>\n",
       "      <td>\"Monsters at Work,\" a series inspired by Pixar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>Commenting on the upcoming Amazon summer sale ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>Congress says it needs to verify whether there...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>This story has been published from a wire agen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION\n",
       "348   This story has been published from a wire agen...        3\n",
       "463   This story has been published from a wire agen...        3\n",
       "587   Facebook, WhatsApp and Twitter have overhauled...        1\n",
       "757   We will leave no stone unturned to make the au...        2\n",
       "835   This story has been published from a wire agen...        1\n",
       "...                                                 ...      ...\n",
       "7453  The whole feels like a giant set, stately and ...        2\n",
       "7462  \"Monsters at Work,\" a series inspired by Pixar...        1\n",
       "7465  Commenting on the upcoming Amazon summer sale ...        1\n",
       "7474  Congress says it needs to verify whether there...        0\n",
       "7553  This story has been published from a wire agen...        1\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['STORY'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2772\n",
       "2    1924\n",
       "0    1686\n",
       "3    1246\n",
       "Name: SECTION, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['SECTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       If you want to answer any question, click on ‘...\n",
       "5       BEIJING: Chinese tech giant Huawei has announc...\n",
       "10      “One would think that their development and te...\n",
       "12      Xiaomi, however, sees the presence of Jio in r...\n",
       "13      The ad reads \"No bells & whistles. No Bezel. N...\n",
       "                              ...                        \n",
       "7617    Sure, the others are slightly faster, have sli...\n",
       "7618    With up to 14.7 million pixels, one billion co...\n",
       "7621    However, as of now, there is no confirmation a...\n",
       "7622    In terms of optics, the back of the Redmi Note...\n",
       "7625    The database has been created after bringing t...\n",
       "Name: STORY, Length: 2772, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['SECTION']==1]['STORY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Story_len'] = train_df['STORY'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        843\n",
       "1        129\n",
       "2        386\n",
       "3        587\n",
       "4        299\n",
       "        ... \n",
       "7623     394\n",
       "7624     136\n",
       "7625     484\n",
       "7626    1927\n",
       "7627     286\n",
       "Name: Story_len, Length: 7628, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa4f0c6f4f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(train_df,col='SECTION')\n",
    "g.map(plt.hist,'Story_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Story_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECTION</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>891.572954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>725.632756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359.120062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>611.605939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Story_len\n",
       "SECTION            \n",
       "0        891.572954\n",
       "1        725.632756\n",
       "2        359.120062\n",
       "3        611.605939"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('SECTION').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['STORY']\n",
    "y = train_df['SECTION']\n",
    "\n",
    "X_pred = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Source'] = 'Train'\n",
    "\n",
    "test_df['Source'] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STORY</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>Story_len</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has also unleashed a wave of changes in the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It can be confusing to pick the right smartpho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mobile application is integrated with a da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have rounded up some of the gadgets that sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>According to researchers, fraud in the mobile ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>The iPhone XS and XS Max share the Apple A12 c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>On the photography front, the Note 5 Pro featu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>UDAY mandated that discoms bring the gap betwe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>Ripple also helps bank customers send money to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  STORY  SECTION  Story_len  \\\n",
       "0     2019 will see gadgets like gaming smartphones ...      NaN        NaN   \n",
       "1     It has also unleashed a wave of changes in the...      NaN        NaN   \n",
       "2     It can be confusing to pick the right smartpho...      NaN        NaN   \n",
       "3     The mobile application is integrated with a da...      NaN        NaN   \n",
       "4     We have rounded up some of the gadgets that sh...      NaN        NaN   \n",
       "...                                                 ...      ...        ...   \n",
       "2743  According to researchers, fraud in the mobile ...      NaN        NaN   \n",
       "2744  The iPhone XS and XS Max share the Apple A12 c...      NaN        NaN   \n",
       "2745  On the photography front, the Note 5 Pro featu...      NaN        NaN   \n",
       "2746  UDAY mandated that discoms bring the gap betwe...      NaN        NaN   \n",
       "2747  Ripple also helps bank customers send money to...      NaN        NaN   \n",
       "\n",
       "     Source  \n",
       "0      Test  \n",
       "1      Test  \n",
       "2      Test  \n",
       "3      Test  \n",
       "4      Test  \n",
       "...     ...  \n",
       "2743   Test  \n",
       "2744   Test  \n",
       "2745   Test  \n",
       "2746   Test  \n",
       "2747   Test  \n",
       "\n",
       "[2748 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[7628:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data\n",
    "def metrics(y_true,y_pred):\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print('\\n\\nAccuracy Score:\\n', accuracy_score(y_true, y_pred))\n",
    "    print('\\n\\nClassification Report: \\n', classification_report(y_true, y_pred))\n",
    "\n",
    "def vectorizer(vector, X):\n",
    "    vc = vector().fit_transform(X)\n",
    "    return vc\n",
    "\n",
    "def split(vc,y):\n",
    "    train = vc[:7628]\n",
    "    test = vc[7628:]\n",
    "    X_train,X_test,y_train, y_test = train_test_split(train, y, test_size=0.3, random_state=123)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test,test\n",
    "    \n",
    "def predictions(model,vector, X, y):\n",
    "    \n",
    "    X_vector = vectorizer(vector, X)\n",
    "    \n",
    "    X_train,X_test,y_train, y_test, test_df= split(X_vector, y)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    actual = [y_train, y_test]\n",
    "    pred = [train_pred, test_pred]\n",
    "    text = ('Train', 'Test')\n",
    "    for i in range(2):\n",
    "        print(f\"-----{text[i]}-----\")\n",
    "        metrics(actual[i], pred[i])\n",
    "        \n",
    "#______#\n",
    "    \n",
    "    final_pred = model.predict(test_df)\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1177   10    2    6]\n",
      " [  16 1919    4   14]\n",
      " [  32   11 1284    0]\n",
      " [   2    3    0  859]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9812699007304738\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1195\n",
      "           1       0.99      0.98      0.99      1953\n",
      "           2       1.00      0.97      0.98      1327\n",
      "           3       0.98      0.99      0.99       864\n",
      "\n",
      "    accuracy                           0.98      5339\n",
      "   macro avg       0.98      0.98      0.98      5339\n",
      "weighted avg       0.98      0.98      0.98      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[477  10   3   1]\n",
      " [  4 801   3  11]\n",
      " [ 27  14 555   1]\n",
      " [  1   7   0 374]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9641764962865881\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       491\n",
      "           1       0.96      0.98      0.97       819\n",
      "           2       0.99      0.93      0.96       597\n",
      "           3       0.97      0.98      0.97       382\n",
      "\n",
      "    accuracy                           0.96      2289\n",
      "   macro avg       0.96      0.96      0.96      2289\n",
      "weighted avg       0.96      0.96      0.96      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes and Count_Vectorizer\n",
    "test_pred = predictions(nb, CountVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred\n",
    "\n",
    "sample_df.to_csv('Pred_nb_count_vc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1146   46    2    1]\n",
      " [   4 1947    1    1]\n",
      " [  25   92 1210    0]\n",
      " [   3  136    0  725]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9417493912717737\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1195\n",
      "           1       0.88      1.00      0.93      1953\n",
      "           2       1.00      0.91      0.95      1327\n",
      "           3       1.00      0.84      0.91       864\n",
      "\n",
      "    accuracy                           0.94      5339\n",
      "   macro avg       0.96      0.93      0.94      5339\n",
      "weighted avg       0.95      0.94      0.94      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[455  35   1   0]\n",
      " [  0 818   1   0]\n",
      " [ 19  92 486   0]\n",
      " [  3  91   0 288]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.8942769768457842\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       491\n",
      "           1       0.79      1.00      0.88       819\n",
      "           2       1.00      0.81      0.90       597\n",
      "           3       1.00      0.75      0.86       382\n",
      "\n",
      "    accuracy                           0.89      2289\n",
      "   macro avg       0.93      0.87      0.89      2289\n",
      "weighted avg       0.91      0.89      0.89      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes and TfidVectorizer\n",
    "test_pred_tfid = predictions(nb, TfidfVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred_tfid\n",
    "\n",
    "sample_df.to_csv('Pred_nb_tfid_vc1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1128   32   26    9]\n",
      " [   7 1918   13   15]\n",
      " [  17   11 1299    0]\n",
      " [   5   20    8  831]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9694699381906724\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1195\n",
      "           1       0.97      0.98      0.98      1953\n",
      "           2       0.97      0.98      0.97      1327\n",
      "           3       0.97      0.96      0.97       864\n",
      "\n",
      "    accuracy                           0.97      5339\n",
      "   macro avg       0.97      0.97      0.97      5339\n",
      "weighted avg       0.97      0.97      0.97      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[437  27  24   3]\n",
      " [  4 793  11  11]\n",
      " [  9  12 574   2]\n",
      " [  3  19   8 352]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9418960244648318\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93       491\n",
      "           1       0.93      0.97      0.95       819\n",
      "           2       0.93      0.96      0.95       597\n",
      "           3       0.96      0.92      0.94       382\n",
      "\n",
      "    accuracy                           0.94      2289\n",
      "   macro avg       0.95      0.94      0.94      2289\n",
      "weighted avg       0.94      0.94      0.94      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistics Regression and HashingVectorizer\n",
    "\n",
    "test_pred_log1 = predictions(lg, HashingVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred_log1\n",
    "\n",
    "sample_df.to_csv('Pred_lg_hash_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1191    4    0    0]\n",
      " [   0 1953    0    0]\n",
      " [   0    0 1327    0]\n",
      " [   0   10    0  854]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9973777861022664\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1195\n",
      "           1       0.99      1.00      1.00      1953\n",
      "           2       1.00      1.00      1.00      1327\n",
      "           3       1.00      0.99      0.99       864\n",
      "\n",
      "    accuracy                           1.00      5339\n",
      "   macro avg       1.00      1.00      1.00      5339\n",
      "weighted avg       1.00      1.00      1.00      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[452  15  24   0]\n",
      " [  4 790  18   7]\n",
      " [  5   6 585   1]\n",
      " [  3   9  10 360]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9554390563564875\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95       491\n",
      "           1       0.96      0.96      0.96       819\n",
      "           2       0.92      0.98      0.95       597\n",
      "           3       0.98      0.94      0.96       382\n",
      "\n",
      "    accuracy                           0.96      2289\n",
      "   macro avg       0.96      0.95      0.95      2289\n",
      "weighted avg       0.96      0.96      0.96      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred_log = predictions(lg, CountVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred_log\n",
    "\n",
    "sample_df.to_csv('Pred_log_count_vc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1162   15   11    7]\n",
      " [   2 1935    5   11]\n",
      " [   9    0 1318    0]\n",
      " [   1    4    1  858]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9876381344821128\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1195\n",
      "           1       0.99      0.99      0.99      1953\n",
      "           2       0.99      0.99      0.99      1327\n",
      "           3       0.98      0.99      0.99       864\n",
      "\n",
      "    accuracy                           0.99      5339\n",
      "   macro avg       0.99      0.99      0.99      5339\n",
      "weighted avg       0.99      0.99      0.99      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[448  23  19   1]\n",
      " [  0 802   9   8]\n",
      " [  8   7 581   1]\n",
      " [  1  11   7 363]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9584971603320227\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       491\n",
      "           1       0.95      0.98      0.97       819\n",
      "           2       0.94      0.97      0.96       597\n",
      "           3       0.97      0.95      0.96       382\n",
      "\n",
      "    accuracy                           0.96      2289\n",
      "   macro avg       0.96      0.95      0.96      2289\n",
      "weighted avg       0.96      0.96      0.96      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistics Regression and Tfid Vectorizer\n",
    "\n",
    "test_pred_tfid = predictions(lg, TfidfVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred_tfid\n",
    "\n",
    "sample_df.to_csv('Pred_lg_tfid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1191    4    0    0]\n",
      " [   0 1953    0    0]\n",
      " [   0    0 1327    0]\n",
      " [   0   10    0  854]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9973777861022664\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1195\n",
      "           1       0.99      1.00      1.00      1953\n",
      "           2       1.00      1.00      1.00      1327\n",
      "           3       1.00      0.99      0.99       864\n",
      "\n",
      "    accuracy                           1.00      5339\n",
      "   macro avg       1.00      1.00      1.00      5339\n",
      "weighted avg       1.00      1.00      1.00      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[410  35  38   8]\n",
      " [ 11 698  58  52]\n",
      " [ 20  47 516  14]\n",
      " [ 18  51  22 291]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.836609873307121\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       491\n",
      "           1       0.84      0.85      0.85       819\n",
      "           2       0.81      0.86      0.84       597\n",
      "           3       0.80      0.76      0.78       382\n",
      "\n",
      "    accuracy                           0.84      2289\n",
      "   macro avg       0.84      0.83      0.83      2289\n",
      "weighted avg       0.84      0.84      0.84      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "test_pred=predictions(dtree, CountVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, ..., 1, 3, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred\n",
    "\n",
    "sample_df.to_csv('Dtree_count_vc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1191    4    0    0]\n",
      " [   0 1953    0    0]\n",
      " [   0    0 1327    0]\n",
      " [   0   10    0  854]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9973777861022664\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1195\n",
      "           1       0.99      1.00      1.00      1953\n",
      "           2       1.00      1.00      1.00      1327\n",
      "           3       1.00      0.99      0.99       864\n",
      "\n",
      "    accuracy                           1.00      5339\n",
      "   macro avg       1.00      1.00      1.00      5339\n",
      "weighted avg       1.00      1.00      1.00      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[409  29  42  11]\n",
      " [ 16 706  46  51]\n",
      " [ 14  44 528  11]\n",
      " [ 14  60  22 286]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.8427260812581914\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87       491\n",
      "           1       0.84      0.86      0.85       819\n",
      "           2       0.83      0.88      0.86       597\n",
      "           3       0.80      0.75      0.77       382\n",
      "\n",
      "    accuracy                           0.84      2289\n",
      "   macro avg       0.84      0.83      0.84      2289\n",
      "weighted avg       0.84      0.84      0.84      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred=predictions(dtree, TfidfVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred\n",
    "\n",
    "sample_df.to_csv('Dtree_tfid_vc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1191    4    0    0]\n",
      " [   0 1953    0    0]\n",
      " [   0    0 1327    0]\n",
      " [   0   10    0  854]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9973777861022664\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1195\n",
      "           1       0.99      1.00      1.00      1953\n",
      "           2       1.00      1.00      1.00      1327\n",
      "           3       1.00      0.99      0.99       864\n",
      "\n",
      "    accuracy                           1.00      5339\n",
      "   macro avg       1.00      1.00      1.00      5339\n",
      "weighted avg       1.00      1.00      1.00      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[436  26  29   0]\n",
      " [  2 782  29   6]\n",
      " [ 13  10 574   0]\n",
      " [  8  25  16 333]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.928352992573176\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       491\n",
      "           1       0.93      0.95      0.94       819\n",
      "           2       0.89      0.96      0.92       597\n",
      "           3       0.98      0.87      0.92       382\n",
      "\n",
      "    accuracy                           0.93      2289\n",
      "   macro avg       0.94      0.92      0.93      2289\n",
      "weighted avg       0.93      0.93      0.93      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "test_pred=predictions(rf, TfidfVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred\n",
    "\n",
    "sample_df.to_csv('rf_tfid_vc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:29:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "-----Train-----\n",
      "Confusion Matrix:\n",
      " [[1191    4    0    0]\n",
      " [   0 1953    0    0]\n",
      " [   0    0 1327    0]\n",
      " [   0   10    0  854]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9973777861022664\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1195\n",
      "           1       0.99      1.00      1.00      1953\n",
      "           2       1.00      1.00      1.00      1327\n",
      "           3       1.00      0.99      0.99       864\n",
      "\n",
      "    accuracy                           1.00      5339\n",
      "   macro avg       1.00      1.00      1.00      5339\n",
      "weighted avg       1.00      1.00      1.00      5339\n",
      "\n",
      "-----Test-----\n",
      "Confusion Matrix:\n",
      " [[442  28  18   3]\n",
      " [  3 777  23  16]\n",
      " [ 12  13 571   1]\n",
      " [  4  18  11 349]]\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      " 0.9344692005242464\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93       491\n",
      "           1       0.93      0.95      0.94       819\n",
      "           2       0.92      0.96      0.94       597\n",
      "           3       0.95      0.91      0.93       382\n",
      "\n",
      "    accuracy                           0.93      2289\n",
      "   macro avg       0.94      0.93      0.93      2289\n",
      "weighted avg       0.94      0.93      0.93      2289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "\n",
    "test_pred=predictions(xgb, TfidfVectorizer, df['STORY'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['SECTION'] = test_pred\n",
    "\n",
    "sample_df.to_csv('xgb_tfid_vc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
